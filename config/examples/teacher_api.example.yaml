# ===========================================
# Teacher Model Configuration (OpenAI Compatible API)
# ===========================================
# Use this for inference with external API (vLLM, OpenAI, etc.)
# Copy to config/teacher_api.yaml and modify as needed

type: "api"
model_type: "default"  # Preprocessor type: deepseek-ocr, deepseek-document, default

# API Settings
api:
  base_url: "http://localhost:8000/v1"  # vLLM server URL
  model_name: "your-model-name"
  api_key: "your-api-key"  # Or use environment variable

# Generation Parameters
generation:
  temperature: 0.1
  max_tokens: 4096
  top_p: 1.0

# Request Settings
request:
  timeout: 120
  max_retries: 3
  concurrent_requests: 4  # Number of parallel API requests

# ===========================================
# Teacher Prompts (key-based)
# ===========================================
# Usage: --task <key_name>
# Student instruction is managed in config/prompts.yaml

prompts:
  # OCR task
  ocr:
    system: |
      You are an OCR assistant. Extract all text from the image accurately.
    user: |
      Extract all text from this image.

  # Document parsing task
  document:
    system: |
      You are a document parsing assistant. Convert the document image to structured Markdown.

      Guidelines:
      - Use ## for section headings
      - Use bullet points for lists
      - Use HTML tables for tabular data
      - Preserve the document structure
    user: |
      Convert this document to Markdown format.

# Output Settings
output:
  format: "jsonl"  # jsonl, json, md
  save_images: false
